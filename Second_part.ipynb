{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southern-belarus",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "In this exercise, we will use a canonical example where GPUs can make a difference. We will look at **matrix multiplication**, concretely at the case of two square matrices to make life easier. For matrices A and B, every element of the result matrix C can be calculated as follows:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/ee372c649dea0a05bf1ace77c9d6faf051d9cc8d)\n",
    "\n",
    "This is an inherently parallel problem, since all elements in the matrix C can be calculated independently at the same. In a first parallel implementation, the idea would be to assign each thread in a block to process a different element of the result matrix C.\n",
    "\n",
    "![Matrix multiplication](https://upload.wikimedia.org/wikipedia/commons/e/eb/Matrix_multiplication_diagram_2.svg)\n",
    "\n",
    "Since we are going to focus in performance, it is better to define matrices A, B and C as linear matrices representing a 2D array. There are two main methods of representing matrices:\n",
    "\n",
    "![Matrix representations](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Row_and_column_major_order.svg/340px-Row_and_column_major_order.svg.png)\n",
    "\n",
    "The format used for this exercise will be **row-major order**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-international",
   "metadata": {},
   "source": [
    "### Matrix multiplication with threads in a block\n",
    "\n",
    "In file [matrix_multiply.cu](/edit/matrix_multiply.cu) you will find a first implementation of square matrix multiplication. This version of matrix multiplication runs on the GPU, but it runs sequentially with a single block and a single thread.\n",
    "\n",
    "When compiled, the program generated accepts the size of the matrix as a single argument which is the width and height of the matrices involved in the multiplication. The time it took to run is also recorded and shown at the end of the exercise. In \n",
    "addition, after performing the multiplication, a submatrix of size 64x64 is also computed on the CPU and the result obtained is checked to verify if there were errors.\n",
    "\n",
    "Test that the program compiles and runs. The command below executes the matrix multiply of 512x512 matrices and checks the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o matrix_multiplication/matrix_multiply matrix_multiplication/matrix_multiply.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run-exclusive.sh ./matrix_multiplication/matrix_multiply 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-imaging",
   "metadata": {},
   "source": [
    "It is time to parallelize using threads in a block. Since the work is conceptually done over 2D, you may use the capability of defining the block dimension in 2D by setting `dim3 block (n_threads, n_threads);`. Bear in mind that there is a limit in the number of threads you may use per block, calculated by multiplying the block dimensions, which on most GPUs is set to be 1024 threads per block in total. \n",
    "\n",
    "* Parallelize the work by using `threadIdx.x` and `threadIdx.y` to iterate over the first two for-loops in the kernel.\n",
    "* Keep the grid dimension to be 1 for now, and optimize the block dimension used to invoke your function.\n",
    "\n",
    "Use the file [matrix_multiply_threads.cu](/edit/matrix_multiply_threads.cu) to write your code. You may look into the [solution](/edit/matrix_multiply_threads_solution.cu) if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o matrix_multiplication/matrix_multiply_threads matrix_multiplication/matrix_multiply_threads.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run-exclusive.sh ./matrix_multiplication/matrix_multiply_threads 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-miller",
   "metadata": {},
   "source": [
    "### Multiple threads and blocks\n",
    "\n",
    "Add now more parallelization by using many blocks in a grid. You should use as many blocks as needed so that every thread is tasked with calculating a single element of the grid.\n",
    "\n",
    "* The number of blocks should be defined as a 2D grid.\n",
    "* The number of blocks should depend on the matrix `size` and the `number of threads`.\n",
    "\n",
    "Write your solution in file [matrix_multiply_grid.cu](/edit/matrix_multiply_grid.cu). Here is the [solution](/edit/matrix_multiply_grid_solution.cu) in case you want to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o matrix_multiplication/matrix_multiply_grid matrix_multiplication/matrix_multiply_grid.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run-exclusive.sh ./matrix_multiplication/matrix_multiply_grid 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-modern",
   "metadata": {},
   "source": [
    "### Shared memory\n",
    "\n",
    "The final step consists in using **shared memory** as an intermediate buffer where data will be available by using a **tiling** method. As you may recall from the lectures, you should follow these steps:\n",
    "\n",
    "* Load the tile from global into shared memory in a coalesced manner.\n",
    "* Synchronize.\n",
    "* Have multiple threads access the data from the shared buffer.\n",
    "* Synchronize.\n",
    "* Move on to the next tile.\n",
    "\n",
    "You will have to define a `tile size` at compile time in order to be able to define the size of the shared memory array. You may use the expression `constexpr int tile_size = 32;` as a starting point at the top of your program.\n",
    "\n",
    "All threads should participate in loading each tile into memory, calculate a partial result in a register, and then move on to the next tile. Visually:\n",
    "\n",
    "![pr](https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/matrix-multiplication-with-shared-memory.png)\n",
    "\n",
    "Use file [matrix_multiply_shared.cu](/edit/matrix_multiply_shared.cu) to write your answer. In case you need to resort to the [solution](/edit/matrix_multiply_grid_solution.cu) you may have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_70 -o matrix_multiplication/matrix_multiply_shared matrix_multiplication/matrix_multiply_shared.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./run-exclusive.sh ./matrix_multiplication/matrix_multiply_shared 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "olive-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author identity unknown\r\n",
      "\r\n",
      "*** Please tell me who you are.\r\n",
      "\r\n",
      "Run\r\n",
      "\r\n",
      "  git config --global user.email \"you@example.com\"\r\n",
      "  git config --global user.name \"Your Name\"\r\n",
      "\r\n",
      "to set your account's default identity.\r\n",
      "Omit --global to set the identity only in this repository.\r\n",
      "\r\n",
      "fatal: unable to auto-detect email address (got 'dcampora@jupyter-dcampora.(none)')\r\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"Added second part with matrix multiplication\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global user.email \"dcampora@cern.ch\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
